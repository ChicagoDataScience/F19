

<!DOCTYPE html>
<html lang="en">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Syllabus</title>

<style>
	body{
		margin:1em auto;
		max-width:40em;
		padding:0 .62em;
		font:1.2em/1.62 sans-serif;
	}
	h1,h2,h3 {
		line-height:1.2;
	}
	@media print{
		body{
			max-width:none
		}
	}
	.venue { font-style: italic; }
	.note { font-style: italic; font-size: x-small; }
</style>

<article>

	<h1>Statistical Models and Methods for Business Analytics</h1>
<h3><center> IDS 575 </center></h3>
<p><span style="color:red">All announcements will be made on the <a href="https://forum.chicagods.com">Forum</a> </span></p>
<h2>Overview</h2>
<p>The goal of this class is to cover the foundations of modern statistics and machine learning methods complementing the data mining focus of IDS 572. In other words, you will get up to speed with the requisite background, as well as the key theoretical underpinnings of modern analytics. We will do so through the lens of statistical machine learning. Lectures will be complemented with hands-on exercises in R.</p>
<h2>Previous Editions</h2>
<ul>
<li><a href="https://chicagodatascience.github.io/s19/575/">Spring 2019</a> (has videos!)</li>
<li><a href="https://chicagodatascience.github.io/s18/575/">Spring 2018</a> (has videos!)</li>
<li><a href="https://chicagodatascience.github.io/f17/575/">Fall 2017</a> (has videos!)</li>
</ul>
<h2>Logistics</h2>
<ul>
<li>Semester: Fall 2019</li>
<li>Lectures: Mondays 6.00 PM to 8.30 PM at DH 220 (location subject to change)</li>
<li>Optional Recitations: TBD</li>
<li>Staff<ul>
<li>Instructor: <a href="http://theja.org">Dr. Theja Tulabandhula</a> </li>
<li>Teaching Assistant: Parshan Pakiman</li>
</ul>
</li>
<li>Online communication: <a href="https://forum.chicagods.com">Forum</a> (sign up needed!)</li>
<li>Offline communication:<ul>
<li>Instructor Office Hours: 1.00 to 2.00 PM at UH 2404</li>
<li>TA Office Hours: TBD</li>
</ul>
</li>
</ul>
<h2>Textbook and Materials</h2>
<ul>
<li>Textbook I: <a href="http://web.stanford.edu/~hastie/ElemStatLearn/">Elements of Statistical Learning II</a>.</li>
<li>Textbook II: <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a>.</li>
<li><a href="https://www.youtube.com/playlist?list=PLzq3B7Hh4uva2qkiTJHjWMkdg_Ng2KYgb">Refresher on Probability</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLzq3B7Hh4uvZpOMDIpBWtOHsgnK0LLkJ-">Refresher on Linear Algebra</a></li>
</ul>
<h2>Software</h2>
<ul>
<li>The <a href="https://cran.r-project.org/index.html">R programming language</a> and the <a href="https://www.rstudio.com/">RStudio</a> IDE.</li>
<li>Learning R: <a href="https://r4ds.had.co.nz/">R for Data Science</a></li>
</ul>
<h2>Schedule (<em>tentative</em>)</h2>
<h4>08/23 and 08/30: Review of the Basics of Probability, Calculus and Linear Algebra (Different Logistics: 3.00 to 6.00 PM at DH 210)</h4>
<h4>08/26 : Supervised Learning: Linear Models and Least Squares, k-Nearest Neighbor Methods</h4>
<ul>
<li>[R]</li>
</ul>
<h4>09/09 : Towards Regression: Statistical Decision Theory, Curse of Dimensionality, Linear Regression, Categorical Variables, Interaction Terms</h4>
<h4>09/16 : Regression I: Bias-variance Trade-off, Subset Selection, Cross-Validation</h4>
<h4>09/23 : Regression II: Ridge Regression, LASSO (Least Absolute Shrinkage and Selection Operator)</h4>
<h4>09/30 : Classification: Linear Discriminant Analysis, Logistic Regression, Model Assessment and Selection: AIC, BIC and Validation</h4>
<h4>10/7 : The Bootstrap, Maximum Likelihood Estimation and Review of Linear Models</h4>
<h4>10/21 : Business applications of regression, classification and likelihood maximization</h4>
<h4>10/28 : Expectation Maximization and Sampling (Markov Chain Monte Carlo)</h4>
<h4>11/04 : Tree Methods, Adaboost and Gradient Boosting</h4>
<h4>11/11 : Random Forests, Multivariate Adaptive Regression Splines and Support Vector Machines</h4>
<h4>11/18 : Kernel Trick, Introduction to Unsupervised Learning, Association Rules</h4>
<h4>11/25 : Unsupervised Learning: Clustering, Principal Component Analysis and Spectral Clustering</h4>
<h4>12/2 : Time Series and Supervised Learning, and the ARMA Model</h4>
<h2>Assignments</h2>
<ol>
<li>09/09: <a href="#">Assignment 1</a> out. Due on 09/22</li>
<li>09/23: <a href="#">Assignment 2</a> out. Due on 10/06 </li>
<li>10/07: <a href="#">Assignment 3</a> out. Due on 10/28</li>
<li>11/04: <a href="#">Assignment 4</a> out. Due on 11/17</li>
<li>11/18: <a href="#">Assignment 5</a> out. Due on 12/01</li>
</ol>
<p>These involve reimplementing statistical techniques and understanding their behavior on interesting datasets. Always mention sources in your assignment solutions. Submission deadline is BEFORE 11.59 PM on the concerned day. Late submissions will have an automatic 20% penalty per day. Use <a href="https://uic.blackboard.com/">Blackboard</a> for uploads.</p>
<h2>Exams</h2>
<ol>
<li>10/14: Exam I (same venue as lectures, and during class hours)</li>
<li>12/09: Exam II (finals week, subject to change)</li>
</ol>
<p>These are closed book, but one 8.5x11-inch handwritten cheatsheet is allowed.  No computers and communication devices are allowed.</p>
<h2>Grades</h2>
<ul>
<li>Assignments: 8% + 8% + 8% + 8% + 8% </li>
<li>Exams: 22% (Exam I) + 30% (Exam II)</li>
<li>Participation: 8% (online and offline)</li>
</ul>
<h2>Miscellaneous Information</h2>
<ul>
<li>This is a 4 credit graduate level course offered by the Information and Decision Sciences department at UIC.</li>
<li>Please see the <a href="http://catalog.uic.edu/ucat/academic-calendar/">academic calendar</a> for the semester timeline.</li>
<li>Students who wish to observe their religious holidays (http://oae.uic.edu/religious-calendar/) should notify the instructor within one week of the first lecture date. </li>
<li>Please contact the instructor at the earliest, if you require accommodations for access to and/or participation in this course.</li>
<li>Please refer to the academic integrity guidelines set by the university.</li>
</ul>

</article>

<footer> 
<small>If you see any errors, please contact the teaching staff.</small>
</footer>

	